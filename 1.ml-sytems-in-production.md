# Chapter 1: Machine Learning Systems in Production 

The algorithm is only a small part of an ML system in production. 

The system also includes the inference where users and developers interact with your system, the data stack to manage your data, the infrastructure to execute the required workloads, and the hardware backend your ML algorithms runs on. 

Ordered from high-level to low: 
1. Inference
2. Data + ML algorithms
3. Infrastructure
4. Hardware

This book doesn't go on ML algorithms but the context around building in machine learning as a whole.

Because of the scale of many ML systems - they consume a massive amount of data, require heavy computational power, and have the potential to affect the lives of so many people. 

When and when not to use machine learning?

ML is not the optimal solution to many problems.
- Is ML necessary here? Is is cost effective? 

Machine learning is an approach to learning complex patterns from existing data nd use these pattens to make predictions on unseen data.

- Learn: The system has the capacity to learn.
- Complex: The patterns are complex.
- Patterns: There are patterns to learn.
- Existing data: data is available, or it's possible to collect data.
- Predictions: It's a predictive problem. 
- Unseen data: The unseen data has to share patterns with the training data.
    - Your unseen data and training data should come from similar distributions.

Some additional characteristics
- It's repetitive: If you're data is few-shot then you have a high chance of getting really good results. 
- It's at scale: ML solutions require non-trivial upfront investments on data, compute, infrastructure, and talent. 
- The patterns are constantly changing: You might get stuck in the past becasue of old/ un-useful data.

When to NOT use machine learning
1. It's unethical.
2. Simpler solutions do the trick. You should always try to start with a simple solution. 
3. One single prediction error can cause devastating consequences. 
4. It's not cost-effective.

Even though the market for consumer ML applications is booming, the majority of ML use cases are still in the enterprise world.

You must understand the end user of everything you are building. An example is enterprise is usually forgiving on higher latency than something like consumer software.

When to use ML: 
1. Fraud detection: If your product or service involves transactions of any value, it'll be susceptible to fraud. You can use ML for anomaly detection.
2. Price Optimization: Estimating the price at a certain time. 
3. Forcast customer demand: So you can prepare a budget, stock inventory, allocate resources, and update pricing strategy. 
4. Reducing customer acquisition cost: by a small amount can result in a large increase in profits.
5. Churn prediction: When specific customer is about to stop using your products or services so that you can take appropriate actions to win them back.
6. Automated support ticket classification: You can classify a support ticket based on many categories.
7. Brand monitoring: Monitoring the value of your brand. 
8. Detect skin cancer / diagnose diabetes: etc.

**ML in research vs in production**
- ML in production is very different from ML in research.

The differences
- Objectives: In research it's model performance, in production is depends on the usecase.
- Computational priority: In research you are focused on fast training with high throughput while in product it's fast inference and low latency.
- Data: In research the data is static while in production the data is constantly shifting.
- Fairness: In research it's good to have while in production it's very improtant.
- Interpretability: In research it's good to have while in production it's important.

Research and leaderboard products have a single objective of model performance.

There are many stakeholders involved in bringing an ML system into production.
- You have to consider the objectives of the engineers. 
- Sales team
- Product team
- Infra team
- The manager

Production have different objectives from research is one of the reasons why successful research projects might not always be used in production.

For many tasks, a small improvement in performance can result in a huge boost in revenue or cost save.

If a simple model can do a reasonable job, complex models must perform significantly better to justify the complexity.

When designing an ML system, peopel who haven't deployed a ML system often make the mistake of focusing entirely on the model development part.

Research prioritizes high throughput wheras production prioritizes low latency.
- Latency: The time it takes from receiving a query to returning the result.
- Throughput: How many queries are processed within a specific period of time.

If your system always processes one query at a time, higher latency means lower throughput.

Most modern distributed systems batch queries to process them together, often concurrently, higher latency might also mean higher throughput times.

Bathcing requires your system to wait for enough queries to arrive in a batch before processing them, which further increases latency.

## Data

In research, the data you are given is very clean. This is not true in industry, you have to optimize the data yourself.

In research, since you don't serve your models to users, you mostly work with historical data, e.g. data that already exists and is stored somewhere. In production, most likely you'll also have to work with data that is being constantly generated by users, systems, adnd third-party data.

In production about 75% of the problem is the data. While in reserach data is 3% of the problem.

This is also a problem of fairness in production as well. Are these models actually being fair? Are these models safe?

ML algorithms don't predict the future, but encode the past, perpetuating the biases in the data and more.

Model interpretability isn't just optional for most ML use cases in the industry, but a requirement.

As of 2019, only 19% of large companies are working to improve the explainability of their algorithms.

While it's important to pursue pure research, most companies can't affort it unless it leads to short-term business applications.

ML systems are part code, part data, and part artifacts created from the two.

The size of ML models gives another channel. These models need a lot of memory to be able to load all of the parameters.

Monitoring and debugging these models in production is also non-trivial.

## Designing ML systems in production

ML systems design is the process of defining all the components of an ML system, including inference, algorithms, data, infrastructure, and hardward, so that the system satisfies specified requirements.

Most systems should have these four characteristics: 
1. Reliable 
2. Scalable
3. Maintainable
4. Adaptable

## Reliable

The system should continue to perform the correct function at the disired level of performance even in the face of adversity (hard or software faults, and even human error).

ML systems fail silently. End users don't even know that the system has failed and might have kept on using it as if it was working.

## Scalability

Scaling isn't just up-scaling -- expanding the resources to handle growth. In ML, it's also important to down-scale -- reducing the resources when not needed.

You want to automatically scale up and down the number of machine depending on usage.

## Maintainability

It's important to stucture your product and set up your infrastructure in a way such that different contributors can work using tools that they are confortable with, instead of one group of contributors forcing their tools onto other groups.

## Adaptability

To adapt to changing data distributions and business requirements, the system should have some capcity for both discovering aspects of performance improvements and allowing updates without service interruption.

## Iterative Process

Developing an ML system is an iterative and, in most cases, never ending process. You do reach the point where you have to put the system into production, but then the system will constantly need to be monitored and updated.

## What deploying a system in production looks like

1. Project scoping
- You lay out the goals & objectives, constraints, and evaluation criteria.
- Stakeholders should be identified and involved.
- Resources should be estimated and allocated.

2. Data engineering
- Data used and generated by ML systems can be large and diverse, which requires scalable infra to process and access it fast and reliably.

3. ML model development
- You need to create training datasets, and possibly label the, then generate features, train models, optimize models, and evalutate them.

4. Deployment
- After a model is deployed, it needs to be made accessible to users.

5. Monitoring and continual learning
- Models need to be monitored for performance decay and maintained to be adaptive to changing environments and changing requirements.

6. Business Analytics
- Model performance needs ot be evaluated against business goals and analyzed to generate business insights.
